{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59fd76ec",
   "metadata": {},
   "source": [
    "## Download and Load the Data\n",
    "We download the data directly from the DropBox link and load them in the Jupyter workspace as Pandas Dataframe. We than call the .head() method to check the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9112a9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import urllib\n",
    "import pandas as pd\n",
    "\n",
    "DOWNLOAD_URL = 'https://www.dropbox.com/s/7nwimmta836si5f/churn.csv?dl=1'\n",
    "CHURN_PATH = os.path.join(\"dataset\", \"churn\")\n",
    "\n",
    "# Download data directly from Dropbox\n",
    "def fetch_data(download_url=DOWNLOAD_URL, path=CHURN_PATH):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    csv_path = os.path.join(path, \"churn.csv\")\n",
    "    urllib.request.urlretrieve(download_url, csv_path)\n",
    "\n",
    "# Load data\n",
    "def load_data(path=CHURN_PATH):\n",
    "    csv_path = os.path.join(path, \"churn.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "fetch_data()\n",
    "churn = load_data()\n",
    "\n",
    "# Check result\n",
    "churn.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c80c6ab",
   "metadata": {},
   "source": [
    "## Assemble Datasets\n",
    "Here we assemble three datasets of different size:\n",
    "\n",
    "- the data_full dataset includes all the variables present in the original dataset except for the CLIENTNUM identifier\n",
    "\n",
    "- the data_best includes only the ten variables that we selected as most correlated with Attrition_Flag from preliminary analysis\n",
    "\n",
    "- the data_mini only includes Total_Trans_Amt and Total_Trans_Ct as they proved the most predictive for the target\n",
    "\n",
    "We also decided to keep an or_data version of the full original set keeping all the unkown rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef53bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute 3 different datasets\n",
    "or_data=churn.drop([\"Unnamed: 0\", \"CLIENTNUM\"], axis=1)\n",
    "data_full=churn.drop([\"Unnamed: 0\", \"CLIENTNUM\"], axis=1)\n",
    "data_best=churn[[\"Attrition_Flag\",\"Gender\",\"Income_Category\",\"Total_Relationship_Count\",\"Months_Inactive_12_mon\",\"Contacts_Count_12_mon\",\"Credit_Limit\",\"Total_Trans_Amt\",\"Total_Trans_Ct\",\"Avg_Utilization_Ratio\"]]\n",
    "data_mini=churn[[\"Attrition_Flag\",\"Total_Trans_Amt\",\"Total_Trans_Ct\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405cdf63",
   "metadata": {},
   "source": [
    "## Delete \"Unknown\" rows\n",
    "Here we define a function that first checks the presence of the Education_Level, Marital_Status, Income_Category in the datasets. It replaces the \"Unknown\" values with Nan and returns the dataset dropping all the NaN values. Notice that this operation was perfomed exclusively on the data_full and data_best datasets as the data_mini does not include any categorical attribute. Moreover this operation was performed only on the Income_Category for the data_best in order to retain as many data points as possible. We also had to reset the index.\n",
    "\n",
    "Than we check wheter the \"Unknown\" values have been correctly removed for both sets and if the Attrition Flag Proportions between Existing and Attriting customers have been retained after the removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebba6a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Unkown with NAN and drop Nan to delete rows\n",
    "import numpy as np\n",
    "\n",
    "unkown_vars = ['Education_Level', 'Marital_Status', 'Income_Category']\n",
    "\n",
    "def replace_unkown(dataset):\n",
    "    for var in unkown_vars:\n",
    "        if var in dataset.columns:\n",
    "            dataset[var] = dataset[var].replace(\"Unknown\", np.NaN)\n",
    "    return dataset.dropna()\n",
    "\n",
    "data_full = replace_unkown(data_full).reset_index(drop=True)\n",
    "data_best = replace_unkown(data_best).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fa9ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double-check for results with values_counts()\n",
    "def check_replace_unkown(dataset):\n",
    "    for var in unkown_vars:\n",
    "        if var in dataset.columns:\n",
    "            print(dataset[var].value_counts())\n",
    "            print('\\n')\n",
    "\n",
    "check_replace_unkown(data_best)\n",
    "print(\"DATAFULL#############\\n\")\n",
    "check_replace_unkown(data_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d24c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if proportions for Attrition_Flag actually resemble those of the original dataset after dropping Unknown\n",
    "prop = data_full[\"Attrition_Flag\"].value_counts() / len(data_full)\n",
    "proptot = churn[\"Attrition_Flag\"].value_counts() / len(churn)\n",
    "\n",
    "print(prop)     # data_full\n",
    "print(\"\\n\")\n",
    "print(proptot)  # original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9923cfc",
   "metadata": {},
   "source": [
    "## Train-Test Splits\n",
    "Here we define two functions to implement both a traditional train_test_split and a StratifiedShuffleSplit split for Attrition Flag of the datasets. Both the methods were .imported from the model_selection module of scikit-learn. We will call the functions in the section \"Select and Train models\" below. We also check the results of the stratified split on the data_full computing the the Attrition Flag Proportions between Existing and Attriting customers on the strat_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d7f3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classic sklearn split \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split(dataset, test_size):\n",
    "    train_set, test_set = train_test_split(dataset, test_size=test_size, random_state=42)\n",
    "    print(\"\\033[1mTrain:\\033[0m\", len(train_set), \"\\t\\033[1mTest:\\033[0m\", len(test_set))\n",
    "    return train_set, test_set\n",
    "\n",
    "train_set, test_set = split(data_full, 0.2) # FULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce67c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified Split based on Attrition flag\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def strat_split(dataset, test_size):\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=42)\n",
    "\n",
    "    for train_index, test_index in split.split(dataset, dataset[\"Attrition_Flag\"]):\n",
    "        strat_train_set = dataset.loc[train_index]\n",
    "        strat_test_set = dataset.loc[test_index]\n",
    "    print(\"\\033[1mTrain:\\033[0m\", len(strat_train_set), \"\\t\\033[1mTest:\\033[0m\", len(strat_test_set))\n",
    "    return strat_train_set, strat_test_set\n",
    "\n",
    "strat_train_set, strat_test_set = strat_split(data_full, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bf5a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if proportions in test_set actually resemble those of the full dataset\n",
    "prop = strat_test_set[\"Attrition_Flag\"].value_counts() / len(strat_test_set)\n",
    "proptot = churn[\"Attrition_Flag\"].value_counts() / len(churn)\n",
    "\n",
    "print(prop)\n",
    "print(\"\\n\")\n",
    "print(proptot)\n",
    "print(\"\\nThe proportions between Attrited and Existing costumers are respected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623b3ea1",
   "metadata": {},
   "source": [
    "## Prepare Data for ML Models\n",
    "In this section we define a few functions to prepare the data for the Machine Learning models:\n",
    "\n",
    "- the sep_pred_target takes as input the train and test sets and splits them both in X (predictors) and y (labels)\n",
    "\n",
    "- the tranformation_pipeline takes as input only the train set of the predictors (X), splits numerical and categorical variables and via the ColumnTransformer applies Standard Scaling to numerical variables and One Hot encoding on categorical variables. It returns the prepared train set. To perform this operations we imported the ColumnTransformer from the compose module and the StandardScaler and the OneHotEncoder from the preprocessing module of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f918bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets separate the predictors and target value PLAIN\n",
    "\n",
    "def sep_pred_target(train_set, test_set):\n",
    "    X = train_set.drop(\"Attrition_Flag\", axis=1)\n",
    "    y = train_set[\"Attrition_Flag\"].copy()\n",
    "\n",
    "    X_test = test_set.drop(\"Attrition_Flag\", axis=1)\n",
    "    y_test = test_set[\"Attrition_Flag\"].copy()\n",
    "    \n",
    "    return X, y, X_test, y_test\n",
    "\n",
    "# Lets separate the predictors and target value STRATIFIED\n",
    "X, y, X_test, y_test = sep_pred_target(train_set, test_set)\n",
    "X_strat_train, y_strat_train, X_strat_test, y_strat_test  = sep_pred_target(strat_train_set, strat_test_set)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb30573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRASFORMATION PIPELINE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Define variables lists\n",
    "cat_vars = ['Attrition_Flag', 'Gender', 'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category']\n",
    "num_vars = [\"Customer_Age\", \"Dependent_count\", \"Months_on_book\", \"Total_Relationship_Count\", \n",
    "              \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\", \"Credit_Limit\", \"Total_Trans_Amt\", \n",
    "             \"Total_Trans_Ct\", \"Avg_Utilization_Ratio\"]\n",
    "\n",
    "def tranformation_pipeline(X):\n",
    "    \n",
    "    lst=[]\n",
    "    for var in cat_vars:\n",
    "        if var in X.columns:\n",
    "            lst.append(var)\n",
    "    #print(lst)\n",
    "\n",
    "    # Split cat and num attributes\n",
    "    X_num = X.drop(lst, axis=1)\n",
    "    X_cat = X.drop(list(X_num.columns), axis=1)\n",
    "\n",
    "    num_attribs = list(X_num.columns)\n",
    "    cat_attribs = list(X_cat.columns)\n",
    "\n",
    "    # Separate col transformations for num and cat\n",
    "    full_pipeline = ColumnTransformer([(\"num\", StandardScaler(), num_attribs),   # STD SCALING for numerical\n",
    "                                       (\"cat\", OneHotEncoder(), cat_attribs),])  # ONE-HOT for categorical\n",
    "\n",
    "    # Final TRAIN dataset (without labels)\n",
    "    X_prep = full_pipeline.fit_transform(X)\n",
    "    \n",
    "    return X_prep\n",
    "\n",
    "X_prep=tranformation_pipeline(X)\n",
    "X_prep_test=tranformation_pipeline(X_test)\n",
    "X_prep_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6877f3e4",
   "metadata": {},
   "source": [
    "## SMOTE\n",
    "Synthetic Minority Oversampling Technique(SMOTE) is an oversampling technique and widely used to handle the imbalanced dataset. This technique synthesizes new data points for minority class (Attrited Customers) and oversample that class. Unfortunately although we were able to run the SMOTE on the prepared train set and the train labels we were not able to feed the resampled data to our machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2075741",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=0)\n",
    "\n",
    "# Train\n",
    "X_resampled, y_resampled = sm.fit_resample(X_prep, y)\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff8a568",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "Here we define a function that takes X_train, y_train, y_test and y_pred as input, compute all the metrics to evaluate our model and return them in a ordered list. We computed the following metrics: \n",
    "\n",
    "- Confusion matrix\n",
    "\n",
    "- Accuracy, Precision, Sensitivity, Specificity (manually computed form CM), Precision and Recall were recomputed with the precision_score and recall_score from scikit-learn just to double-check our results.\n",
    "\n",
    "- Cross Validation (cv=3) scores, mean and standard deviation of the scores.\n",
    "\n",
    "- f1 score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc1f8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Compute function to analyze models performance\n",
    "def metrics(X_train, y_train, y_test, y_pred):\n",
    "    \n",
    "    lst=[]\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    accuracy=(cm[1,1]+cm[0,0])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])\n",
    "    precision=(cm[1,1]/(cm[1,1]+cm[0,1]))\n",
    "    sensitivity=cm[1,1]/(cm[1,1]+cm[1,0])\n",
    "    specificity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "    \n",
    "    # Precision and Recall\n",
    "    prec = round(precision_score(y_test, y_pred, pos_label='Existing Customer'),3)\n",
    "    recall = round(recall_score(y_test,y_pred, pos_label='Existing Customer'),3)\n",
    "    \n",
    "    # Accuracy with crossval\n",
    "    cv_scores=cross_val_score(classifier, X_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "    mean=round(cv_scores.mean(),3)\n",
    "    std=round(cv_scores.std(),3)\n",
    "\n",
    "    # F1 score\n",
    "    f1 = round(f1_score(y_test, y_pred, pos_label='Existing Customer'),3)\n",
    "\n",
    "    # ROC and AUC\n",
    "    \n",
    "    # Put it all in a list\n",
    "    lst.append(f\"test_size={size}\"+\"\\n\"+\"Accuracy: \"+str(round(accuracy*100,2))+\n",
    "                    \" Precision: \"+str(round(precision*100,2))+\n",
    "                    \" Sensitivity: \"+str(round(sensitivity*100,2))+\n",
    "                    \" Specificity: \"+str(round(specificity*100,2))+\"\\n\"\n",
    "                    \"CrossVal scores: \"+str(cv_scores)+\n",
    "                    \" Mean e std: \"+str(mean)+\"\\t\"+str(std)+\"\\n\"\n",
    "                    \"Prec and recall: \"+str(prec)+\"\\t\"+str(recall)+\n",
    "                    \"\\tF1 score: \"+str(f1))\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b1a7a0",
   "metadata": {},
   "source": [
    "## Select and Train Models\n",
    "Here we run a for loop to fit the models with three different test sizes (0.2, 0.25, 0.30). We ran the for loop on the data_full set but to run it on the data_best,the data_mini or on the original dataset without the unknown values removal, it would be sufficient to substitute the dataset name where highlighted in comment. \n",
    "\n",
    "- We first split the dataset with boht the plain and the stratified splits, we prepare the data by calling the transformation pipeline function defined above (Standard Scaling, One Hot) and define the final prepared variables.\n",
    "\n",
    "- Than we feed four different models from scikit-learn with the prepared data: Logistic Regression, Support Vector Machines, Decision Trees, Random Forest. We fit the models wiht both the plain and stratified data\n",
    "\n",
    "- We compute the metrics for each model by calling the metrics function defined above and print the perfomance measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4f192f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###### Model Fitting and Testing\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "test_sizes=[0.20,0.25,0.30]\n",
    "\n",
    "\n",
    "for size in test_sizes:\n",
    "    \n",
    "    ############################################### DATA PREPARATION\n",
    "    # Split\n",
    "    train_set, test_set = split(data_best, size)                     # SUBSTITUTE DATASET with DATA_BEST, MINI, OR\n",
    "    strat_train_set, strat_test_set = strat_split(data_best, size)   # SUBSTITUTE DATASET with DATA_BEST, MINI, OR\n",
    "    \n",
    "    # Lets separate the predictors and target value\n",
    "    X, y, X_test, y_test = sep_pred_target(train_set, test_set)\n",
    "    X_strat, y_strat, X_strat_test, y_strat_test  = sep_pred_target(strat_train_set, strat_test_set)\n",
    "\n",
    "    # Transformation Pipeline\n",
    "    X_prep = tranformation_pipeline(X)\n",
    "    X_prep_test = tranformation_pipeline(X_test)\n",
    "    \n",
    "    X_prep_strat = tranformation_pipeline(X_strat)\n",
    "    X_prep_test_strat = tranformation_pipeline(X_strat_test)\n",
    "    \n",
    "    # FINAL renaming\n",
    "    X_train = X_prep\n",
    "    y_train = y\n",
    "    X_test = X_prep_test\n",
    "    y_test = y_test\n",
    "    \n",
    "    X_train_strat = X_prep_strat\n",
    "    y_train_strat = y_strat\n",
    "    X_test_strat = X_prep_test_strat\n",
    "    y_test_strat = y_strat_test\n",
    "    \n",
    "    ############################### LOGISTIC REGRESSION\n",
    "    # Fitting Logistic to Train set\n",
    "    classifier = LogisticRegression(random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Metrics\n",
    "    print(\"\\nLOGISTIC\\n\")\n",
    "    logistic = metrics(X_train, y_train, y_test, y_pred)\n",
    "    for x in logistic:\n",
    "        print(x)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    ############################### LOGISTIC REGRESSION STRATIFIED\n",
    "    # Fitting Logistic to Train set\n",
    "    classifier = LogisticRegression(random_state = 0)\n",
    "    classifier.fit(X_train_strat, y_train_strat)\n",
    "    # Predicting the Test set results\n",
    "    y_pred_strat = classifier.predict(X_test_strat)\n",
    "    \n",
    "    # Metrics\n",
    "    logisticstr = metrics(X_train_strat, y_train_strat, y_test_strat, y_pred_strat)\n",
    "    for x in logisticstr:\n",
    "        print(x)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "    ################################## SVM\n",
    "    # Fitting SVM to the Training set\n",
    "    classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    # Predicting the Test set results\n",
    "    y_pred_svm = classifier.predict(X_test)\n",
    "    \n",
    "    # Metrics\n",
    "    print(\"\\nSVM\\n\")\n",
    "    svm = metrics(X_train, y_train, y_test, y_pred_svm)\n",
    "    for x in svm:\n",
    "        print(x)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "    ################################## SVM STRATIFIED\n",
    "    # Fitting Logistic to Train set\n",
    "    classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "    classifier.fit(X_train_strat, y_train_strat)\n",
    "    # Predicting the Test set results\n",
    "    y_pred_strat = classifier.predict(X_test_strat)\n",
    "    \n",
    "    # Metrics\n",
    "    svm_str = metrics(X_train_strat, y_train_strat, y_test_strat, y_pred_strat)\n",
    "    for x in svm_str:\n",
    "        print(x)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "    ################################## DECISION TREE CLASSIFICATION\n",
    "    classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    # entropy for homogenous node split\n",
    "    classifier.fit(X_train, y_train)\n",
    "    # Predicting the Test set results\n",
    "    y_pred_dt = classifier.predict(X_test)\n",
    "    \n",
    "    print(\"\\nDECISION TREE\\n\")\n",
    "    dt = metrics(X_train, y_train, y_test, y_pred_dt)\n",
    "    for x in dt:\n",
    "        print(x)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    ################################## DECISION TREE STRATIFIED\n",
    "    # Fitting Logistic to Train set\n",
    "    classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    classifier.fit(X_train_strat, y_train_strat)\n",
    "    # Predicting the Test set results\n",
    "    y_pred_strat = classifier.predict(X_test_strat)\n",
    "    \n",
    "    # Metrics\n",
    "    dt_str = metrics(X_train_strat, y_train_strat, y_test_strat, y_pred_strat)\n",
    "    for x in dt_str:\n",
    "        print(x)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    ################################## RANDOM FOREST CLASSIFICATION\n",
    "    classifier = RandomForestClassifier(n_estimators = 300, criterion = 'entropy', random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred_rf = classifier.predict(X_test)\n",
    "    \n",
    "    print(\"\\nRANDOM FOREST\\n\")\n",
    "    rf = metrics(X_train, y_train, y_test, y_pred_rf)\n",
    "    for x in rf:\n",
    "        print(x)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    ################################## RANDOM FOREST STRATIFIED\n",
    "    # Fitting Logistic to Train set\n",
    "    classifier = RandomForestClassifier(n_estimators = 300, criterion = 'entropy', random_state = 0)\n",
    "    classifier.fit(X_train_strat, y_train_strat)\n",
    "    # Predicting the Test set results\n",
    "    y_pred_strat = classifier.predict(X_test_strat)\n",
    "    \n",
    "    # Metrics\n",
    "    rf_str = metrics(X_train_strat, y_train_strat, y_test_strat, y_pred_strat)\n",
    "    for x in rf_str:\n",
    "        print(x)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567ef8ac",
   "metadata": {},
   "source": [
    "## ROC curves\n",
    "Here we define a function to plot the ROC curve of the classifier based on the confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de7d6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC e AUC\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Precision Recall curve\n",
    "def plot_prec_rec(classifier):\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    y_pred_prob = classifier.predict_proba(X_test)[:,0]\n",
    "\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test, y_pred_prob, pos_label='Existing Customer')\n",
    "\n",
    "    def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "        plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "\n",
    "    plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "# ROC\n",
    "def plot_roc(classifier):\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    y_pred_prob = classifier.predict_proba(X_test)[:,0]\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob, pos_label=\"Existing Customer\")\n",
    "    \n",
    "    def plot_roc(fpr, tpr, thresholds):\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.plot(fpr, tpr, linewidth=2)\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "    plot_roc(fpr, tpr, thresholds)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421b8ee5",
   "metadata": {},
   "source": [
    "## Hyperparameters Fine Tuning\n",
    "We used the RandomizedSearchCV method from sklearn.model_selection module to fine tune the Random Forest classifier hyperparameters. Our goal was to to inspect whether we could obtain even better performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a2278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 300, criterion = 'entropy', random_state = 0)\n",
    "\n",
    "distributions = {'bootstrap': [True, False],\n",
    "               'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
    "               'max_features': ['auto', 'sqrt'],\n",
    "               'min_samples_leaf': [1, 2, 4],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'n_estimators': [130, 180, 230, 300]}\n",
    "\n",
    "clf = RandomizedSearchCV(classifier, distributions, random_state=0)\n",
    "search = clf.fit(X_train, y_train)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140b512b",
   "metadata": {},
   "source": [
    "## Final Model\n",
    "Finally we fit the Randomized Search seach.best_estimator_ with the data_best dataset and analyze the final results and the ROC curve obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd090a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = split(data_best, 0.2)                    \n",
    "# Separate the predictors and target value\n",
    "X, y, X_test, y_test = sep_pred_target(train_set, test_set)\n",
    "# Transformation Pipeline\n",
    "X_prep = tranformation_pipeline(X)\n",
    "X_prep_test = tranformation_pipeline(X_test)\n",
    "# FINAL renaming\n",
    "X_train = X_prep\n",
    "y_train = y\n",
    "X_test = X_prep_test\n",
    "y_test = y_test\n",
    "\n",
    "######################################### \n",
    "\n",
    "classifier = search.best_estimator_\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred_rf = classifier.predict(X_test)\n",
    "\n",
    "print(\"\\nRANDOM FOREST\\n\")\n",
    "rf = metrics(X_train, y_train, y_test, y_pred_rf)\n",
    "for x in rf:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2d59d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prec_rec(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1df3e47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_roc(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d048db3b",
   "metadata": {},
   "source": [
    "## Results Plots\n",
    "To further visualize our classifiers performance we decided to plot decision boundaries for the two variables of Tot_Trans_Count over the Tot_Trans_Amt for both the training and the test set. We repeated this procedure for both the Decision Tree and the Random Forest classifier. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f873a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare data\n",
    "data_best = data_best[[\"Attrition_Flag\",\"Total_Trans_Amt\",\"Total_Trans_Ct\"]]\n",
    "flag=[]\n",
    "for x in data_best.iloc[:, 0].values:\n",
    "    if x==\"Existing Customer\":\n",
    "        flag.append(1)\n",
    "    else:\n",
    "        flag.append(0)\n",
    "        \n",
    "data_best[\"flag\"]=flag\n",
    "\n",
    "X = data_best.iloc[:,[1,2]].values\n",
    "y = data_best.iloc[:, 3].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Visualising the Training set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_train, y_train\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Decision Tree (Training set)')\n",
    "plt.xlabel('Total_Trans_Amt')\n",
    "plt.ylabel('Total_Trans_Ct')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualising the Test set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_test, y_test\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Decision Tree (Test set)')\n",
    "plt.xlabel('Total_Trans_Amt')\n",
    "plt.ylabel('Total_Trans_Ct')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f195e53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare data\n",
    "data_best = data_best[[\"Attrition_Flag\",\"Total_Trans_Amt\",\"Total_Trans_Ct\"]]\n",
    "flag=[]\n",
    "for x in data_best.iloc[:, 0].values:\n",
    "    if x==\"Existing Customer\":\n",
    "        flag.append(1)\n",
    "    else:\n",
    "        flag.append(0)\n",
    "        \n",
    "data_best[\"flag\"]=flag\n",
    "\n",
    "X = data_best.iloc[:,[1,2]].values\n",
    "y = data_best.iloc[:, 3].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "classifier = search.best_estimator_\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Visualising the Training set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_train, y_train\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Random Forest (Training set)')\n",
    "plt.xlabel('Total_Trans_Amt')\n",
    "plt.ylabel('Total_Trans_Ct')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualising the Test set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_test, y_test\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Random Forest (Test set)')\n",
    "plt.xlabel('Total_Trans_Amt')\n",
    "plt.ylabel('Total_Trans_Ct')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
